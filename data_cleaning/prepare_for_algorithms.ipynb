{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"label\"\n",
    "one_hot_encode = True\n",
    "data_file = \"H5N1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe_for_ml(df, target_column=None, one_hot_encode=True):\n",
    "    \"\"\"\n",
    "    Prepare a pandas DataFrame for machine learning algorithms.\n",
    "    - Normalizes numerical features\n",
    "    - Optionally one-hot encodes categorical features\n",
    "    - Optionally separates target variable\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame to prepare\n",
    "    target_column : str, optional\n",
    "        Name of the target column to separate\n",
    "    one_hot_encode : bool, optional\n",
    "        Whether to one-hot encode categorical features\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_processed: pandas.DataFrame\n",
    "        The processed DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Separate target if specified\n",
    "    y = None\n",
    "    if target_column and target_column in df_processed.columns:\n",
    "        y = df_processed[target_column].replace({\"nz\": 0, \"hzoon\": 1})\n",
    "        df_processed = df_processed.drop(columns=[target_column])\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df_processed.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "    # Handle missing values\n",
    "    df_processed[numerical_cols] = df_processed[numerical_cols].fillna(df_processed[numerical_cols].median())\n",
    "    for col in categorical_cols:\n",
    "        df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])\n",
    "\n",
    "    # Normalize numerical features\n",
    "    if numerical_cols:\n",
    "        scaler = StandardScaler()\n",
    "        df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    if categorical_cols and one_hot_encode:\n",
    "        df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "    # If we have a target column, add it back to the processed dataframe\n",
    "    if target_column and y is not None:\n",
    "        df_processed[target_column] = y\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Species', 'Location', 'gid', 'title', 'date', 'subtype',\n",
       "       'label', 'src', 'TT_p2_Bias_HA',\n",
       "       ...\n",
       "       'PAAC_Xc1.A_PB2', 'PAAC_Xc1.P_PB2', 'PAAC_Xc2.lambda3_PB2',\n",
       "       'PAAC_Xc1.F_PB2', 'PAAC_Xc1.C_PB2', 'PAAC_Xc1.I_PB2', 'PAAC_Xc1.W_PB2',\n",
       "       'PAAC_Xc1.R_PB2', 'PAAC_Xc1.H_PB2', 'SpeciesBins'],\n",
       "      dtype='object', length=970)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path.join(\"..\", \"split_data\", \"subtypes\", data_file))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\n",
    "    columns=[\"Unnamed: 0\", \"Species\", \"gid\", \"title\", \"date\", \"subtype\", \"src\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/g9qrr1y94z1gtsqjsbkjw2m40000gs/T/ipykernel_51629/3237007222.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = df_processed[target_column].replace({\"nz\": 0, \"hzoon\": 1})\n"
     ]
    }
   ],
   "source": [
    "processed_data = prepare_dataframe_for_ml(data, target_column=target_column, one_hot_encode=one_hot_encode)\n",
    "processed_data.to_csv(path.join(\"..\", \"cleaned_data\", f\"processed_ohe_{one_hot_encode}_{data_file}\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
