{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model\n",
    "The purpose of this notebook is to take the top performing models run them on what we believe to be the most effective data. We then search through the hyperparameter space of the models to try and optimise F1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = path.join(\"..\", \"data\", \"zoonosis_dataset_full.csv\")\n",
    "target_column = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe_for_ml(df, target_column=None, one_hot_encode=True):\n",
    "    \"\"\"\n",
    "    Prepare a pandas DataFrame for machine learning algorithms.\n",
    "    - Normalizes numerical features\n",
    "    - Optionally one-hot encodes categorical features\n",
    "    - Optionally separates target variable\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame to prepare\n",
    "    target_column : str, optional\n",
    "        Name of the target column to separate\n",
    "    one_hot_encode : bool, optional\n",
    "        Whether to one-hot encode categorical features\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df_processed: pandas.DataFrame\n",
    "        The processed DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Separate target if specified\n",
    "    y = None\n",
    "    if target_column and target_column in df_processed.columns:\n",
    "        y = df_processed[target_column].replace({\"nz\": 0, \"hzoon\": 1})\n",
    "        df_processed = df_processed.drop(columns=[target_column])\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df_processed.select_dtypes(\n",
    "        include=[\"int64\", \"float64\"]\n",
    "    ).columns.tolist()\n",
    "    categorical_cols = df_processed.select_dtypes(\n",
    "        include=[\"object\", \"category\", \"bool\"]\n",
    "    ).columns.tolist()\n",
    "\n",
    "    # Handle missing values\n",
    "    df_processed[numerical_cols] = df_processed[numerical_cols].fillna(\n",
    "        df_processed[numerical_cols].median()\n",
    "    )\n",
    "    for col in categorical_cols:\n",
    "        df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])\n",
    "\n",
    "    # Normalize numerical features\n",
    "    if numerical_cols:\n",
    "        scaler = StandardScaler()\n",
    "        df_processed[numerical_cols] = scaler.fit_transform(\n",
    "            df_processed[numerical_cols]\n",
    "        )\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    if categorical_cols and one_hot_encode:\n",
    "        df_processed = pd.get_dummies(\n",
    "            df_processed, columns=categorical_cols, drop_first=False\n",
    "        )\n",
    "\n",
    "    # If we have a target column, add it back to the processed dataframe\n",
    "    if target_column and y is not None:\n",
    "        df_processed[target_column] = y\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unimportant_columns(dataframe, columns_to_keep):\n",
    "    return dataframe[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "processed_data = prepare_dataframe_for_ml(data, target_column=target_column)\n",
    "y = processed_data[\"label\"]\n",
    "X = processed_data.drop(columns=[\"label\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightGBM = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results\n",
    "Show results of training across various values in grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Model Performance\n",
    "On temporally split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get False Positives"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
